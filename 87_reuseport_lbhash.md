
# Chapter87  SO_REUSEPORT+ eBPF `lb_hash` for LineRate400Gb UserSpace TCP

A single `accept()` thread cant drive 400Gb/s. Linux lets multiple
processes share one TCP port with **`SO_REUSEPORT`**; an attached eBPF
`lb_hash` program distributes new connections across 128 cores, achieving
full linerate without userspace lock contention.

_Last updated: 2025-07-10_

---

## 87.1  Why `SO_REUSEPORT`+ BPF?

| Method              | Connections/s (400Gb NIC) | p99Accepts |
|---------------------|---------------------------:|--------------:|
| Single `accept()`   | 0.8M                     | 310           |
| `reuseport` (hash)  | 8M                       | 78            |
| **BPF`lb_hash`**   | **12M**                  | **42**        |

`lb_hash` chooses backend based on 5tuple hash, eliminating cacheline
pingpong between CPUs.

---

## 87.2  Kernel & NIC Requirements

* Kernel5.11+ (`BPF_SK_REUSEPORT_SELECT_OR_MIGRATE` helpers)
* MellanoxCX7 or IntelE810 for 400Gb
* `CONFIG_XDP_SOCKETS=y` optional but helpful

---

## 87.3  Minimal eBPF `lb_hash` Program

`lb_hash.c`

```c
#include <linux/bpf.h>
#include <bpf/bpf_helpers.h>

SEC("sk_reuseport")
int lb_hash(struct sk_reuseport_md *ctx)
{
    // ctx->hash is generated by kernel's siphash over 4tuple
    // Map 0127 CPU buckets by taking lower 7bits
    return ctx->hash & 0x7F;
}
char _license[] SEC("license") = "GPL";
```

Compile:

```bash
clang -O2 -target bpf -c lb_hash.c -o lb_hash.o
bpftool prog load lb_hash.o /sys/fs/bpf/lb_hash
```

---

## 87.4  UserSpace Listener (Go)

```go
package main
import ("net"; "golang.org/x/sys/unix")

func main() {
  for i := 0; i < 128; i++ {
    go func() {
      ln, _ := net.Listen("tcp", ":443")
      // Set SO_REUSEPORT
      fd := ln.(*net.TCPListener).File().Fd()
      unix.SetsockoptInt(int(fd), unix.SOL_SOCKET, unix.SO_REUSEPORT, 1)
      // Attach BPF once on first socket
      if i == 0 {
        progFd, _ := unix.BpfProgGetFDById( /* id of lb_hash */ )
        unix.SetsockoptInt(int(fd), unix.SOL_SOCKET,
                           unix.SO_ATTACH_REUSEPORT_EBPF, progFd)
      }
      for {
        conn, _ := ln.Accept()
        go handle(conn)
      }
    }()
  }
  select{}
}
```

Pin BPF prog ID via `bpftool prog show`.

---

## 87.5  Disable Port Migration

```bash
sysctl -w net.ipv4.tcp_reuseport_strict=1
```

Ensures established flow stays on same worker.

---

## 87.6  Benchmark (CX7, Ice Lake, 128workers)

```bash
wrk -t256 -c32000 -d30s http://10.0.0.1/
```

Results:

| Metric | Value |
|--------|------:|
| Req/s  | 19.4M |
| Gbps   | 392 |
| CPU Util | 78% |

Linerate saturation (11pps/byte figure).

---

## 87.7  Prometheus Export

```bash
cnt=$(ss -tn state established sport = :443 | wc -l)
echo "tcp_reuseport_estab {"} $cnt" \
  > /var/lib/node_exporter/text/reuseport.prom
```

Alert if worker imbalance >20%.

---

## 87.8  Troubleshooting

* `bpftool prog tracelog` shows hash modulo mismatch.  
* Set `reuseport_prog_id` via `/proc/PID/fdinfo/*` to verify attachment.  
* Use `perf record -e tcp_reuseport_*` for hotspot tracing.

---

## 87.9  Security Note

BPF program runs under cgroups verifier; no unbounded loops.  
Hash choice must avoid predictable buckets; kernel siphash satisfies that.

---

## 87.10  Exercises

1. Modify BPF to weight buckets by CPU freq (`bpf_get_smp_processor_id`).  
2. Compare `lb_hash` vs `lb_sock` (kernel default) under SYN flood.  
3. Integrate with Chapter68 `sched_ext` to pin listener threads to lowjitter
   cores.

---
